import{_ as a,c as n,b as e,o as l}from"./chunks/framework.B1z0IdBH.js";const y=JSON.parse('{"title":"æ•ˆç‡è¯„ä¼°","description":"","frontmatter":{},"headers":[{"level":2,"title":"1. æ¨¡å‹èµ„æº","slug":"_1-æ¨¡å‹èµ„æº","link":"#_1-æ¨¡å‹èµ„æº","children":[]},{"level":2,"title":"2. ç¯å¢ƒå®‰è£…","slug":"_2-ç¯å¢ƒå®‰è£…","link":"#_2-ç¯å¢ƒå®‰è£…","children":[]},{"level":2,"title":"3. æ‰§è¡Œæµ‹è¯•","slug":"_3-æ‰§è¡Œæµ‹è¯•","link":"#_3-æ‰§è¡Œæµ‹è¯•","children":[{"level":3,"title":"æ–¹æ³•1ï¼šä½¿ç”¨Speed Benchmarkå·¥å…·æµ‹è¯•","slug":"æ–¹æ³•1-ä½¿ç”¨speed-benchmarkå·¥å…·æµ‹è¯•","link":"#æ–¹æ³•1-ä½¿ç”¨speed-benchmarkå·¥å…·æµ‹è¯•","children":[]},{"level":3,"title":"æ–¹æ³•2ï¼šä½¿ç”¨è„šæœ¬æµ‹è¯•","slug":"æ–¹æ³•2-ä½¿ç”¨è„šæœ¬æµ‹è¯•","link":"#æ–¹æ³•2-ä½¿ç”¨è„šæœ¬æµ‹è¯•","children":[]}]},{"level":2,"title":"æ³¨æ„äº‹é¡¹","slug":"æ³¨æ„äº‹é¡¹","link":"#æ³¨æ„äº‹é¡¹","children":[]}],"relativePath":"guide/speed-benchmark/README_zh.md","filePath":"guide/speed-benchmark/README_zh.md"}'),o={name:"guide/speed-benchmark/README_zh.md"};function p(t,s,r,c,F,i){return l(),n("div",null,s[0]||(s[0]=[e('<h1 id="æ•ˆç‡è¯„ä¼°" tabindex="-1">æ•ˆç‡è¯„ä¼° <a class="header-anchor" href="#æ•ˆç‡è¯„ä¼°" aria-label="Permalink to &quot;æ•ˆç‡è¯„ä¼°&quot;">â€‹</a></h1><p>æœ¬æ–‡ä»‹ç»Qwen2.5ç³»åˆ—æ¨¡å‹ï¼ˆåŸå§‹æ¨¡å‹å’Œé‡åŒ–æ¨¡å‹ï¼‰çš„æ•ˆç‡æµ‹è¯•æµç¨‹ï¼Œè¯¦ç»†æŠ¥å‘Šå¯å‚è€ƒ <a href="https://qwen.readthedocs.io/en/latest/benchmark/speed_benchmark.html" target="_blank" rel="noreferrer">Qwen2.5æ¨¡å‹æ•ˆç‡è¯„ä¼°æŠ¥å‘Š</a>ã€‚</p><h2 id="_1-æ¨¡å‹èµ„æº" tabindex="-1">1. æ¨¡å‹èµ„æº <a class="header-anchor" href="#_1-æ¨¡å‹èµ„æº" aria-label="Permalink to &quot;1. æ¨¡å‹èµ„æº&quot;">â€‹</a></h2><p>å¯¹äºæ‰˜ç®¡åœ¨HuggingFaceä¸Šçš„æ¨¡å‹ï¼Œå¯å‚è€ƒ <a href="https://huggingface.co/collections/Qwen/qwen25-66e81a666513e518adb90d9e" target="_blank" rel="noreferrer">Qwen2.5æ¨¡å‹-HuggingFace</a>ã€‚</p><p>å¯¹äºæ‰˜ç®¡åœ¨ModelScopeä¸Šçš„æ¨¡å‹ï¼Œå¯å‚è€ƒ <a href="https://modelscope.cn/collections/Qwen25-dbc4d30adb768" target="_blank" rel="noreferrer">Qwen2.5æ¨¡å‹-ModelScope</a>ã€‚</p><h2 id="_2-ç¯å¢ƒå®‰è£…" tabindex="-1">2. ç¯å¢ƒå®‰è£… <a class="header-anchor" href="#_2-ç¯å¢ƒå®‰è£…" aria-label="Permalink to &quot;2. ç¯å¢ƒå®‰è£…&quot;">â€‹</a></h2><p>ä½¿ç”¨HuggingFace transformersæ¨ç†ï¼Œå®‰è£…ç¯å¢ƒå¦‚ä¸‹ï¼š</p><div class="language-shell"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki github-dark vp-code" tabindex="0"><code><span class="line"><span style="color:#B392F0;">conda</span><span style="color:#9ECBFF;"> create</span><span style="color:#79B8FF;"> -n</span><span style="color:#9ECBFF;"> qwen_perf_transformers</span><span style="color:#9ECBFF;"> python=</span><span style="color:#79B8FF;">3.10</span></span>\n<span class="line"><span style="color:#B392F0;">conda</span><span style="color:#9ECBFF;"> activate</span><span style="color:#9ECBFF;"> qwen_perf_transformers</span></span>\n<span class="line"></span>\n<span class="line"><span style="color:#B392F0;">pip</span><span style="color:#9ECBFF;"> install</span><span style="color:#9ECBFF;"> torch==</span><span style="color:#79B8FF;">2.3.1</span></span>\n<span class="line"><span style="color:#B392F0;">pip</span><span style="color:#9ECBFF;"> install</span><span style="color:#9ECBFF;"> git+https://github.com/AutoGPTQ/AutoGPTQ.git@v0.7.1</span></span>\n<span class="line"><span style="color:#B392F0;">pip</span><span style="color:#9ECBFF;"> install</span><span style="color:#9ECBFF;"> git+https://github.com/Dao-AILab/flash-attention.git@v2.5.8</span></span>\n<span class="line"><span style="color:#B392F0;">pip</span><span style="color:#9ECBFF;"> install</span><span style="color:#79B8FF;"> -r</span><span style="color:#9ECBFF;"> requirements-perf-transformers.txt</span></span></code></pre></div><div class="important custom-block github-alert"><p class="custom-block-title">IMPORTANT</p><p></p><ul><li>å¯¹äº <code>flash-attention</code>ï¼Œæ‚¨å¯ä»¥ä» <a href="https://github.com/Dao-AILab/flash-attention/releases/tag/v2.5.8" target="_blank" rel="noreferrer">GitHub å‘å¸ƒé¡µé¢</a> ä½¿ç”¨é¢„ç¼–è¯‘çš„ wheel åŒ…è¿›è¡Œå®‰è£…ï¼Œæˆ–è€…ä»æºä»£ç å®‰è£…ï¼Œåè€…éœ€è¦ä¸€ä¸ªå…¼å®¹çš„ CUDA ç¼–è¯‘å™¨ã€‚ <ul><li>å®é™…ä¸Šï¼Œæ‚¨å¹¶ä¸éœ€è¦å•ç‹¬å®‰è£… <code>flash-attention</code>ã€‚å®ƒå·²ç»è¢«é›†æˆåˆ°äº† <code>torch</code> ä¸­ä½œä¸º <code>sdpa</code> çš„åç«¯å®ç°ã€‚</li></ul></li><li>è‹¥è¦ä½¿ <code>auto_gptq</code> ä½¿ç”¨é«˜æ•ˆçš„å†…æ ¸ï¼Œæ‚¨éœ€è¦ä»æºä»£ç å®‰è£…ï¼Œå› ä¸ºé¢„ç¼–è¯‘çš„ wheel åŒ…ä¾èµ–äºä¸ä¹‹ä¸å…¼å®¹çš„ <code>torch</code> ç‰ˆæœ¬ã€‚ä»æºä»£ç å®‰è£…åŒæ ·éœ€è¦ä¸€ä¸ªå…¼å®¹çš„ CUDA ç¼–è¯‘å™¨ã€‚</li><li>è‹¥è¦ä½¿ <code>autoawq</code> ä½¿ç”¨é«˜æ•ˆçš„å†…æ ¸ï¼Œæ‚¨éœ€è¦å®‰è£… <code>autoawq-kernels</code>ï¼Œè¯¥ç»„ä»¶åº”å½“ä¼šè‡ªåŠ¨å®‰è£…ã€‚å¦‚æœæœªè‡ªåŠ¨å®‰è£…ï¼Œè¯·è¿è¡Œ <code>pip install autoawq-kernels</code> è¿›è¡Œæ‰‹åŠ¨å®‰è£…ã€‚</li></ul></div><p>ä½¿ç”¨vLLMæ¨ç†ï¼Œå®‰è£…ç¯å¢ƒå¦‚ä¸‹ï¼š</p><div class="language-shell"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki github-dark vp-code" tabindex="0"><code><span class="line"><span style="color:#B392F0;">conda</span><span style="color:#9ECBFF;"> create</span><span style="color:#79B8FF;"> -n</span><span style="color:#9ECBFF;"> qwen_perf_vllm</span><span style="color:#9ECBFF;"> python=</span><span style="color:#79B8FF;">3.10</span></span>\n<span class="line"><span style="color:#B392F0;">conda</span><span style="color:#9ECBFF;"> activate</span><span style="color:#9ECBFF;"> qwen_perf_vllm</span></span>\n<span class="line"></span>\n<span class="line"><span style="color:#B392F0;">pip</span><span style="color:#9ECBFF;"> install</span><span style="color:#79B8FF;"> -r</span><span style="color:#9ECBFF;"> requirements-perf-vllm.txt</span></span></code></pre></div><h2 id="_3-æ‰§è¡Œæµ‹è¯•" tabindex="-1">3. æ‰§è¡Œæµ‹è¯• <a class="header-anchor" href="#_3-æ‰§è¡Œæµ‹è¯•" aria-label="Permalink to &quot;3. æ‰§è¡Œæµ‹è¯•&quot;">â€‹</a></h2><p>ä¸‹é¢ä»‹ç»ä¸¤ç§æ‰§è¡Œæµ‹è¯•çš„æ–¹æ³•ï¼Œåˆ†åˆ«æ˜¯ä½¿ç”¨è„šæœ¬æµ‹è¯•å’Œä½¿ç”¨Speed Benchmarkå·¥å…·è¿›è¡Œæµ‹è¯•ã€‚</p><h3 id="æ–¹æ³•1-ä½¿ç”¨speed-benchmarkå·¥å…·æµ‹è¯•" tabindex="-1">æ–¹æ³•1ï¼šä½¿ç”¨Speed Benchmarkå·¥å…·æµ‹è¯• <a class="header-anchor" href="#æ–¹æ³•1-ä½¿ç”¨speed-benchmarkå·¥å…·æµ‹è¯•" aria-label="Permalink to &quot;æ–¹æ³•1ï¼šä½¿ç”¨Speed Benchmarkå·¥å…·æµ‹è¯•&quot;">â€‹</a></h3><p>ä½¿ç”¨<a href="https://github.com/modelscope/evalscope" target="_blank" rel="noreferrer">EvalScope</a>å¼€å‘çš„Speed Benchmarkå·¥å…·è¿›è¡Œæµ‹è¯•ï¼Œæ”¯æŒè‡ªåŠ¨ä»modelscopeä¸‹è½½æ¨¡å‹å¹¶è¾“å‡ºæµ‹è¯•ç»“æœï¼Œä¹Ÿæ”¯æŒæŒ‡å®šæ¨¡å‹æœåŠ¡çš„urlè¿›è¡Œæµ‹è¯•ï¼Œå…·ä½“è¯·å‚è€ƒ<a href="https://evalscope.readthedocs.io/zh-cn/latest/user_guides/stress_test/speed_benchmark.html" target="_blank" rel="noreferrer">ğŸ“–ä½¿ç”¨æŒ‡å—</a>ã€‚</p><p><strong>å®‰è£…ä¾èµ–</strong></p><div class="language-shell"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki github-dark vp-code" tabindex="0"><code><span class="line"><span style="color:#B392F0;">pip</span><span style="color:#9ECBFF;"> install</span><span style="color:#9ECBFF;"> &#39;evalscope[perf]&#39;</span><span style="color:#79B8FF;"> -U</span></span></code></pre></div><h4 id="huggingface-transformersæ¨ç†" tabindex="-1">HuggingFace transformersæ¨ç† <a class="header-anchor" href="#huggingface-transformersæ¨ç†" aria-label="Permalink to &quot;HuggingFace transformersæ¨ç†&quot;">â€‹</a></h4><p>æ‰§è¡Œå‘½ä»¤å¦‚ä¸‹ï¼š</p><div class="language-shell"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki github-dark vp-code" tabindex="0"><code><span class="line"><span style="color:#E1E4E8;">CUDA_VISIBLE_DEVICES</span><span style="color:#F97583;">=</span><span style="color:#9ECBFF;">0</span><span style="color:#B392F0;"> evalscope</span><span style="color:#9ECBFF;"> perf</span><span style="color:#79B8FF;"> \\</span></span>\n<span class="line"><span style="color:#79B8FF;"> --parallel</span><span style="color:#79B8FF;"> 1</span><span style="color:#79B8FF;"> \\</span></span>\n<span class="line"><span style="color:#79B8FF;"> --model</span><span style="color:#9ECBFF;"> Qwen/Qwen2.5-0.5B-Instruct</span><span style="color:#79B8FF;"> \\</span></span>\n<span class="line"><span style="color:#79B8FF;"> --attn-implementation</span><span style="color:#9ECBFF;"> flash_attention_2</span><span style="color:#79B8FF;"> \\</span></span>\n<span class="line"><span style="color:#79B8FF;"> --log-every-n-query</span><span style="color:#79B8FF;"> 5</span><span style="color:#79B8FF;"> \\</span></span>\n<span class="line"><span style="color:#79B8FF;"> --connect-timeout</span><span style="color:#79B8FF;"> 6000</span><span style="color:#79B8FF;"> \\</span></span>\n<span class="line"><span style="color:#79B8FF;"> --read-timeout</span><span style="color:#79B8FF;"> 6000</span><span style="color:#79B8FF;"> \\</span></span>\n<span class="line"><span style="color:#79B8FF;"> --max-tokens</span><span style="color:#79B8FF;"> 2048</span><span style="color:#79B8FF;"> \\</span></span>\n<span class="line"><span style="color:#79B8FF;"> --min-tokens</span><span style="color:#79B8FF;"> 2048</span><span style="color:#79B8FF;"> \\</span></span>\n<span class="line"><span style="color:#79B8FF;"> --api</span><span style="color:#9ECBFF;"> local</span><span style="color:#79B8FF;"> \\</span></span>\n<span class="line"><span style="color:#79B8FF;"> --dataset</span><span style="color:#9ECBFF;"> speed_benchmark</span></span></code></pre></div><h4 id="vllmæ¨ç†" tabindex="-1">vLLMæ¨ç† <a class="header-anchor" href="#vllmæ¨ç†" aria-label="Permalink to &quot;vLLMæ¨ç†&quot;">â€‹</a></h4><div class="language-shell"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki github-dark vp-code" tabindex="0"><code><span class="line"><span style="color:#E1E4E8;">CUDA_VISIBLE_DEVICES</span><span style="color:#F97583;">=</span><span style="color:#9ECBFF;">0</span><span style="color:#B392F0;"> evalscope</span><span style="color:#9ECBFF;"> perf</span><span style="color:#79B8FF;"> \\</span></span>\n<span class="line"><span style="color:#79B8FF;"> --parallel</span><span style="color:#79B8FF;"> 1</span><span style="color:#79B8FF;"> \\</span></span>\n<span class="line"><span style="color:#79B8FF;"> --model</span><span style="color:#9ECBFF;"> Qwen/Qwen2.5-0.5B-Instruct</span><span style="color:#79B8FF;"> \\</span></span>\n<span class="line"><span style="color:#79B8FF;"> --log-every-n-query</span><span style="color:#79B8FF;"> 1</span><span style="color:#79B8FF;"> \\</span></span>\n<span class="line"><span style="color:#79B8FF;"> --connect-timeout</span><span style="color:#79B8FF;"> 60000</span><span style="color:#79B8FF;"> \\</span></span>\n<span class="line"><span style="color:#79B8FF;"> --read-timeout</span><span style="color:#79B8FF;"> 60000</span><span style="color:#79B8FF;">\\</span></span>\n<span class="line"><span style="color:#79B8FF;"> --max-tokens</span><span style="color:#79B8FF;"> 2048</span><span style="color:#79B8FF;"> \\</span></span>\n<span class="line"><span style="color:#79B8FF;"> --min-tokens</span><span style="color:#79B8FF;"> 2048</span><span style="color:#79B8FF;"> \\</span></span>\n<span class="line"><span style="color:#79B8FF;"> --api</span><span style="color:#9ECBFF;"> local_vllm</span><span style="color:#79B8FF;"> \\</span></span>\n<span class="line"><span style="color:#79B8FF;"> --dataset</span><span style="color:#9ECBFF;"> speed_benchmark</span></span></code></pre></div><h4 id="å‚æ•°è¯´æ˜" tabindex="-1">å‚æ•°è¯´æ˜ <a class="header-anchor" href="#å‚æ•°è¯´æ˜" aria-label="Permalink to &quot;å‚æ•°è¯´æ˜&quot;">â€‹</a></h4><ul><li><code>--parallel</code> è®¾ç½®å¹¶å‘è¯·æ±‚çš„workeræ•°é‡ï¼Œéœ€å›ºå®šä¸º1ã€‚</li><li><code>--model</code> æµ‹è¯•æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼Œä¹Ÿå¯ä¸ºæ¨¡å‹IDï¼Œæ”¯æŒè‡ªåŠ¨ä»modelscopeä¸‹è½½æ¨¡å‹ï¼Œä¾‹å¦‚Qwen/Qwen2.5-0.5B-Instructã€‚</li><li><code>--attn-implementation</code> è®¾ç½®attentionå®ç°æ–¹å¼ï¼Œå¯é€‰å€¼ä¸ºflash_attention_2|eager|sdpaã€‚</li><li><code>--log-every-n-query</code>: è®¾ç½®æ¯nä¸ªè¯·æ±‚æ‰“å°ä¸€æ¬¡æ—¥å¿—ã€‚</li><li><code>--connect-timeout</code>: è®¾ç½®è¿æ¥è¶…æ—¶æ—¶é—´ï¼Œå•ä½ä¸ºç§’ã€‚</li><li><code>--read-timeout</code>: è®¾ç½®è¯»å–è¶…æ—¶æ—¶é—´ï¼Œå•ä½ä¸ºç§’ã€‚</li><li><code>--max-tokens</code>: è®¾ç½®æœ€å¤§è¾“å‡ºé•¿åº¦ï¼Œå•ä½ä¸ºtokenã€‚</li><li><code>--min-tokens</code>: è®¾ç½®æœ€å°è¾“å‡ºé•¿åº¦ï¼Œå•ä½ä¸ºtokenï¼›ä¸¤ä¸ªå‚æ•°åŒæ—¶è®¾ç½®ä¸º2048åˆ™æ¨¡å‹å›ºå®šè¾“å‡ºé•¿åº¦ä¸º2048ã€‚</li><li><code>--api</code>: è®¾ç½®æ¨ç†æ¥å£ï¼Œæœ¬åœ°æ¨ç†å¯é€‰å€¼ä¸ºlocal|local_vllmã€‚</li><li><code>--dataset</code>: è®¾ç½®æµ‹è¯•æ•°æ®é›†ï¼Œå¯é€‰å€¼ä¸ºspeed_benchmark|speed_benchmark_longã€‚</li></ul><h4 id="æµ‹è¯•ç»“æœ" tabindex="-1">æµ‹è¯•ç»“æœ <a class="header-anchor" href="#æµ‹è¯•ç»“æœ" aria-label="Permalink to &quot;æµ‹è¯•ç»“æœ&quot;">â€‹</a></h4><p>æµ‹è¯•ç»“æœè¯¦è§<code>outputs/{model_name}/{timestamp}/speed_benchmark.json</code>æ–‡ä»¶ï¼Œå…¶ä¸­åŒ…å«æ‰€æœ‰è¯·æ±‚ç»“æœå’Œæµ‹è¯•å‚æ•°ã€‚</p><h3 id="æ–¹æ³•2-ä½¿ç”¨è„šæœ¬æµ‹è¯•" tabindex="-1">æ–¹æ³•2ï¼šä½¿ç”¨è„šæœ¬æµ‹è¯• <a class="header-anchor" href="#æ–¹æ³•2-ä½¿ç”¨è„šæœ¬æµ‹è¯•" aria-label="Permalink to &quot;æ–¹æ³•2ï¼šä½¿ç”¨è„šæœ¬æµ‹è¯•&quot;">â€‹</a></h3><h4 id="huggingface-transformersæ¨ç†-1" tabindex="-1">HuggingFace transformersæ¨ç† <a class="header-anchor" href="#huggingface-transformersæ¨ç†-1" aria-label="Permalink to &quot;HuggingFace transformersæ¨ç†&quot;">â€‹</a></h4><ul><li>ä½¿ç”¨HuggingFace hub</li></ul><div class="language-shell"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki github-dark vp-code" tabindex="0"><code><span class="line"><span style="color:#B392F0;">python</span><span style="color:#9ECBFF;"> speed_benchmark_transformers.py</span><span style="color:#79B8FF;"> --model_id_or_path</span><span style="color:#9ECBFF;"> Qwen/Qwen2.5-0.5B-Instruct</span><span style="color:#79B8FF;"> --context_length</span><span style="color:#79B8FF;"> 1</span><span style="color:#79B8FF;"> --gpus</span><span style="color:#79B8FF;"> 0</span><span style="color:#79B8FF;"> --outputs_dir</span><span style="color:#9ECBFF;"> outputs/transformers</span></span>\n<span class="line"></span>\n<span class="line"><span style="color:#6A737D;"># æŒ‡å®šHF_ENDPOINT</span></span>\n<span class="line"><span style="color:#E1E4E8;">HF_ENDPOINT</span><span style="color:#F97583;">=</span><span style="color:#9ECBFF;">https://hf-mirror.com</span><span style="color:#B392F0;"> python</span><span style="color:#9ECBFF;"> speed_benchmark_transformers.py</span><span style="color:#79B8FF;"> --model_id_or_path</span><span style="color:#9ECBFF;"> Qwen/Qwen2.5-0.5B-Instruct</span><span style="color:#79B8FF;"> --context_length</span><span style="color:#79B8FF;"> 1</span><span style="color:#79B8FF;"> --gpus</span><span style="color:#79B8FF;"> 0</span><span style="color:#79B8FF;"> --outputs_dir</span><span style="color:#9ECBFF;"> outputs/transformers</span></span></code></pre></div><ul><li>ä½¿ç”¨ModelScope hub</li></ul><div class="language-shell"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki github-dark vp-code" tabindex="0"><code><span class="line"><span style="color:#B392F0;">python</span><span style="color:#9ECBFF;"> speed_benchmark_transformers.py</span><span style="color:#79B8FF;"> --model_id_or_path</span><span style="color:#9ECBFF;"> Qwen/Qwen2.5-0.5B-Instruct</span><span style="color:#79B8FF;"> --context_length</span><span style="color:#79B8FF;"> 1</span><span style="color:#79B8FF;"> --gpus</span><span style="color:#79B8FF;"> 0</span><span style="color:#79B8FF;"> --use_modelscope</span><span style="color:#79B8FF;"> --outputs_dir</span><span style="color:#9ECBFF;"> outputs/transformers</span></span></code></pre></div><p>å‚æ•°è¯´æ˜ï¼š</p><pre><code>`--model_id_or_path`: æ¨¡å‹IDæˆ–æœ¬åœ°è·¯å¾„ï¼Œ å¯é€‰å€¼å‚è€ƒ`æ¨¡å‹èµ„æº`ç« èŠ‚  \n`--context_length`: è¾“å…¥é•¿åº¦ï¼Œå•ä½ä¸ºtokenæ•°ï¼›å¯é€‰å€¼ä¸º1, 6144, 14336, 30720, 63488, 129024ï¼›å…·ä½“å¯å‚è€ƒ`Qwen2.5æ¨¡å‹æ•ˆç‡è¯„ä¼°æŠ¥å‘Š`  \n`--generate_length`: ç”Ÿæˆtokenæ•°é‡ï¼›é»˜è®¤ä¸º2048\n`--gpus`: ç­‰ä»·äºç¯å¢ƒå˜é‡CUDA_VISIBLE_DEVICESï¼Œä¾‹å¦‚`0,1,2,3`ï¼Œ`4,5`  \n`--use_modelscope`: å¦‚æœè®¾ç½®è¯¥å€¼ï¼Œåˆ™ä½¿ç”¨ModelScopeåŠ è½½æ¨¡å‹ï¼Œå¦åˆ™ä½¿ç”¨HuggingFace  \n`--outputs_dir`: è¾“å‡ºç›®å½•ï¼Œ é»˜è®¤ä¸º`outputs/transformers`  \n</code></pre><h4 id="vllmæ¨ç†-1" tabindex="-1">vLLMæ¨ç† <a class="header-anchor" href="#vllmæ¨ç†-1" aria-label="Permalink to &quot;vLLMæ¨ç†&quot;">â€‹</a></h4><ul><li>ä½¿ç”¨HuggingFace hub</li></ul><div class="language-shell"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki github-dark vp-code" tabindex="0"><code><span class="line"><span style="color:#B392F0;">python</span><span style="color:#9ECBFF;"> speed_benchmark_vllm.py</span><span style="color:#79B8FF;"> --model_id_or_path</span><span style="color:#9ECBFF;"> Qwen/Qwen2.5-0.5B-Instruct</span><span style="color:#79B8FF;"> --context_length</span><span style="color:#79B8FF;"> 1</span><span style="color:#79B8FF;"> --max_model_len</span><span style="color:#79B8FF;"> 32768</span><span style="color:#79B8FF;"> --gpus</span><span style="color:#79B8FF;"> 0</span><span style="color:#79B8FF;"> --gpu_memory_utilization</span><span style="color:#79B8FF;"> 0.9</span><span style="color:#79B8FF;"> --outputs_dir</span><span style="color:#9ECBFF;"> outputs/vllm</span></span>\n<span class="line"></span>\n<span class="line"><span style="color:#6A737D;"># æŒ‡å®šHF_ENDPOINT</span></span>\n<span class="line"><span style="color:#E1E4E8;">HF_ENDPOINT</span><span style="color:#F97583;">=</span><span style="color:#9ECBFF;">https://hf-mirror.com</span><span style="color:#B392F0;"> python</span><span style="color:#9ECBFF;"> speed_benchmark_vllm.py</span><span style="color:#79B8FF;"> --model_id_or_path</span><span style="color:#9ECBFF;"> Qwen/Qwen2.5-0.5B-Instruct</span><span style="color:#79B8FF;"> --context_length</span><span style="color:#79B8FF;"> 1</span><span style="color:#79B8FF;"> --max_model_len</span><span style="color:#79B8FF;"> 32768</span><span style="color:#79B8FF;"> --gpus</span><span style="color:#79B8FF;"> 0</span><span style="color:#79B8FF;"> --gpu_memory_utilization</span><span style="color:#79B8FF;"> 0.9</span><span style="color:#79B8FF;"> --outputs_dir</span><span style="color:#9ECBFF;"> outputs/vllm</span></span></code></pre></div><ul><li>ä½¿ç”¨ModelScope hub</li></ul><div class="language-shell"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki github-dark vp-code" tabindex="0"><code><span class="line"><span style="color:#B392F0;">python</span><span style="color:#9ECBFF;"> speed_benchmark_vllm.py</span><span style="color:#79B8FF;"> --model_id_or_path</span><span style="color:#9ECBFF;"> Qwen/Qwen2.5-0.5B-Instruct</span><span style="color:#79B8FF;"> --context_length</span><span style="color:#79B8FF;"> 1</span><span style="color:#79B8FF;"> --max_model_len</span><span style="color:#79B8FF;"> 32768</span><span style="color:#79B8FF;"> --gpus</span><span style="color:#79B8FF;"> 0</span><span style="color:#79B8FF;"> --use_modelscope</span><span style="color:#79B8FF;"> --gpu_memory_utilization</span><span style="color:#79B8FF;"> 0.9</span><span style="color:#79B8FF;"> --outputs_dir</span><span style="color:#9ECBFF;"> outputs/vllm</span></span></code></pre></div><p>å‚æ•°è¯´æ˜ï¼š</p><pre><code>`--model_id_or_path`: æ¨¡å‹IDæˆ–æœ¬åœ°è·¯å¾„ï¼Œ å¯é€‰å€¼å‚è€ƒ`æ¨¡å‹èµ„æº`ç« èŠ‚  \n`--context_length`: è¾“å…¥é•¿åº¦ï¼Œå•ä½ä¸ºtokenæ•°ï¼›å¯é€‰å€¼ä¸º1, 6144, 14336, 30720, 63488, 129024ï¼›å…·ä½“å¯å‚è€ƒ`Qwen2.5æ¨¡å‹æ•ˆç‡è¯„ä¼°æŠ¥å‘Š`  \n`--generate_length`: ç”Ÿæˆtokenæ•°é‡ï¼›é»˜è®¤ä¸º2048\n`--max_model_len`: æ¨¡å‹æœ€å¤§é•¿åº¦ï¼Œå•ä½ä¸ºtokenæ•°ï¼›é»˜è®¤ä¸º32768  \n`--gpus`: ç­‰ä»·äºç¯å¢ƒå˜é‡CUDA_VISIBLE_DEVICESï¼Œä¾‹å¦‚`0,1,2,3`ï¼Œ`4,5`   \n`--use_modelscope`: å¦‚æœè®¾ç½®è¯¥å€¼ï¼Œåˆ™ä½¿ç”¨ModelScopeåŠ è½½æ¨¡å‹ï¼Œå¦åˆ™ä½¿ç”¨HuggingFace  \n`--gpu_memory_utilization`: GPUå†…å­˜åˆ©ç”¨ç‡ï¼Œå–å€¼èŒƒå›´ä¸º(0, 1]ï¼›é»˜è®¤ä¸º0.9  \n`--outputs_dir`: è¾“å‡ºç›®å½•ï¼Œ é»˜è®¤ä¸º`outputs/vllm`  \n`--enforce_eager`: æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨eageræ¨¡å¼ï¼›é»˜è®¤ä¸ºFalse  \n</code></pre><h4 id="æµ‹è¯•ç»“æœ-1" tabindex="-1">æµ‹è¯•ç»“æœ <a class="header-anchor" href="#æµ‹è¯•ç»“æœ-1" aria-label="Permalink to &quot;æµ‹è¯•ç»“æœ&quot;">â€‹</a></h4><p>æµ‹è¯•ç»“æœè¯¦è§<code>outputs</code>ç›®å½•ä¸‹çš„æ–‡ä»¶ï¼Œé»˜è®¤åŒ…æ‹¬<code>transformers</code>å’Œ<code>vllm</code>ä¸¤ä¸ªç›®å½•ï¼Œåˆ†åˆ«å­˜æ”¾HuggingFace transformerså’ŒvLLMçš„æµ‹è¯•ç»“æœã€‚</p><h2 id="æ³¨æ„äº‹é¡¹" tabindex="-1">æ³¨æ„äº‹é¡¹ <a class="header-anchor" href="#æ³¨æ„äº‹é¡¹" aria-label="Permalink to &quot;æ³¨æ„äº‹é¡¹&quot;">â€‹</a></h2><ol><li>å¤šæ¬¡æµ‹è¯•ï¼Œå–å¹³å‡å€¼ï¼Œå…¸å‹å€¼ä¸º3æ¬¡</li><li>æµ‹è¯•å‰è¯·ç¡®ä¿GPUå¤„äºç©ºé—²çŠ¶æ€ï¼Œé¿å…å…¶ä»–ä»»åŠ¡å½±å“æµ‹è¯•ç»“æœ</li></ol>',45)]))}const h=a(o,[["render",p]]);export{y as __pageData,h as default};
